{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we exlore the co-occurrence of keywords across a set of temporal subsets to detect patterns of change in co-occurrence.\n",
    "\n",
    "Temporal subsets are defined according to key events in the timeline of covid19 pandemic in the UK:\n",
    "\n",
    "- up to 23 March 2020 (excluded): pre-lockdown\n",
    "- 23 March to 10 May 2020: strict lockdown\n",
    "- 11 May 2020 onwards: post- strict lockdown (lockdown eases)\n",
    "\n",
    "Note that there are additional dates that we may have considered (e.g., 14 March 2020 \"herd immunity\" approach is mentioned, 13 June 2020 \"social bubbles\" introduced, 15 June non-essential shops reopen) but that would create temporal sub-windows with little amount of data.\n",
    "\n",
    "We will:\n",
    "\n",
    "- [keyword class] Classify keywords according to their normalised corpus frequency and relative document frequency values, for each of the three main time windows\n",
    "- [co-occurrence] For each temporal window, calculate the co-occurrence of keyword pairs as Positive Pointwise Mutual Information and Simpson coefficient\n",
    "- Identify changes in keyword class and keyword co-occurrence across the temporal windows.\n",
    "- Create networks of keyword co-occurrences for each of the three temporal windows and compare network and nodes characteristics across the three.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/alessiatosi/DS_projects/behavioural-sci-perception/docs/ext/keywords.yaml has been successfully loaded as a dict\n",
      "/Users/alessiatosi/DS_projects/behavioural-sci-perception/docs/ext/subkw_to_kw_map.yaml has been successfully loaded as a dict\n"
     ]
    }
   ],
   "source": [
    "from src.news_media.get_keywords_trend import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['NgramRange', 'Actors', 'BehavSci', 'Behav_ins', 'Behav_chan', 'Behav_pol', 'Behav_anal', 'Psych', 'Econ_behav', 'Econ_irrational', 'Nudge', 'Nudge_choice', 'Nudge_pater', 'Covid', 'Fatigue', 'Immunity'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CONFIG.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import UK's news articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_uk = NewsArticles(country=\"uk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`news_uk` is a `NewsArticles` class instance, with the following public attributes and methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['allwords_raw_tf',\n",
       " 'country',\n",
       " 'data',\n",
       " 'dates',\n",
       " 'expand_dict',\n",
       " 'get_num_ngrams',\n",
       " 'kword_docfreq_week',\n",
       " 'kword_rawfreq',\n",
       " 'kword_rawfreq_week',\n",
       " 'kword_reldocfreq_week',\n",
       " 'kword_relfreq_week',\n",
       " 'kword_rfrdf_week',\n",
       " 'kword_yn_occurrence',\n",
       " 'subkword_raw_tf',\n",
       " 'unigram_count_perdoc']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[d for d in dir(news_uk) if not d.startswith(\"_\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`news_uk.data` contains the original dataset of articles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(464, 13)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_uk.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extract data needed for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_uk.subkword_raw_tf\n",
    "kword_rawfreqs = news_uk.kword_rawfreq.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "kword_df = news_uk.kword_yn_occurrence.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group data into time windows\n",
    "\n",
    "According to dates: before 23 March, from 23 March to 10 May, from 11 May onwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiIndex([(  0, '2020-01-23', 149),\n",
       "            (  1, '2020-01-23', 336),\n",
       "            (  2, '2020-01-23', 295),\n",
       "            (  3, '2020-01-23', 185),\n",
       "            (  4, '2020-01-26', 123),\n",
       "            (  5, '2020-01-26', 272),\n",
       "            (  6, '2020-01-27', 658),\n",
       "            (  7, '2020-01-28', 194),\n",
       "            (  8, '2020-01-29', 158),\n",
       "            (  9, '2020-01-29',  78),\n",
       "            ...\n",
       "            (454, '2020-05-10', 352),\n",
       "            (455, '2020-05-10',  46),\n",
       "            (456, '2020-05-10', 111),\n",
       "            (457, '2020-05-10', 210),\n",
       "            (458, '2020-05-10', 234),\n",
       "            (459, '2020-05-10', 207),\n",
       "            (460, '2020-05-10', 137),\n",
       "            (461, '2020-05-10', 275),\n",
       "            (462, '2020-05-10', 150),\n",
       "            (463, '2020-05-10', 215)],\n",
       "           names=['id', 'pub_date', 'word_count'], length=464)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kword_rawfreqs.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_weeks(date):\n",
    "    \"\"\"Assigns and labels weeks to a time window.\"\"\"\n",
    "    if date <= datetime.strptime(\"2020-03-22\", '%Y-%m-%d'):\n",
    "        return \"before-lockdown\"\n",
    "    if (date > datetime.strptime(\"2020-03-22\", '%Y-%m-%d')) and (date <= datetime.strptime(\"2020-05-10\", '%Y-%m-%d')):\n",
    "        return \"lockdown\"\n",
    "    if date <= datetime.strptime(\"2020-05-10\", '%Y-%m-%d'):\n",
    "        return \"post-lockdown\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indexes as columns\n",
    "kword_rawfreqs.reset_index(['pub_date'], inplace=True)\n",
    "kword_df.reset_index(['pub_date'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "kword_rawfreqs[\"time_window\"] = kword_rawfreqs.pub_date.apply(label_weeks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "kword_df[\"time_window\"] = kword_df.pub_date.apply(label_weeks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "kword_df.set_index([kword_df.index, kword_df.pub_date, kword_df.time_window], inplace=True, drop=True)\n",
    "kword_df.drop(['pub_date', 'time_window'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "kword_rawfreqs.set_index([kword_rawfreqs.index, kword_rawfreqs.pub_date, kword_rawfreqs.time_window], inplace=True, drop=True)\n",
    "kword_rawfreqs.drop(['pub_date', 'time_window'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keywords corpus frequency per time window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count of keyword occurrences devided by total word count in each time window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "kword_rawfreqs_agg = kword_rawfreqs.reset_index(['id', 'word_count']).groupby('time_window').agg(\n",
    "    word_count=('word_count', 'sum')).merge(\n",
    "                        kword_rawfreqs.groupby('time_window').sum(),\n",
    "                        on='time_window')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_count</th>\n",
       "      <th>american_behav_scientists</th>\n",
       "      <th>behav_analysis</th>\n",
       "      <th>behav_change</th>\n",
       "      <th>behav_econ</th>\n",
       "      <th>behav_insight</th>\n",
       "      <th>behav_insights_team</th>\n",
       "      <th>behav_science</th>\n",
       "      <th>chater</th>\n",
       "      <th>halpern</th>\n",
       "      <th>michie</th>\n",
       "      <th>nudge</th>\n",
       "      <th>nudge_choice</th>\n",
       "      <th>nudge_paternalism</th>\n",
       "      <th>psychology</th>\n",
       "      <th>spi-b</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time_window</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>before-lockdown</th>\n",
       "      <td>48496</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>67</td>\n",
       "      <td>104</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>44</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lockdown</th>\n",
       "      <td>85084</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>24</td>\n",
       "      <td>8</td>\n",
       "      <td>52</td>\n",
       "      <td>224</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>85</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 word_count  american_behav_scientists  behav_analysis  \\\n",
       "time_window                                                              \n",
       "before-lockdown       48496                         17               1   \n",
       "lockdown              85084                         23               5   \n",
       "\n",
       "                 behav_change  behav_econ  behav_insight  behav_insights_team  \\\n",
       "time_window                                                                     \n",
       "before-lockdown             5          10              2                   67   \n",
       "lockdown                   30          24              8                   52   \n",
       "\n",
       "                 behav_science  chater  halpern  michie  nudge  nudge_choice  \\\n",
       "time_window                                                                    \n",
       "before-lockdown            104       1       35      44     47             1   \n",
       "lockdown                   224       1       30      85     52             0   \n",
       "\n",
       "                 nudge_paternalism  psychology  spi-b  \n",
       "time_window                                            \n",
       "before-lockdown                  1          47      7  \n",
       "lockdown                         1         100     83  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kword_rawfreqs_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "kword_agg_nkf = kword_rawfreqs_agg.iloc[:, 1:].div(kword_rawfreqs_agg.word_count, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "kword_agg_nkf_long = pd.melt(\n",
    "                    kword_agg_nkf.reset_index(),\n",
    "                    id_vars=['time_window'],\n",
    "                    var_name='kword',\n",
    "                    value_name='nkf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_window</th>\n",
       "      <th>kword</th>\n",
       "      <th>nkf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>before-lockdown</td>\n",
       "      <td>american_behav_scientists</td>\n",
       "      <td>0.000351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lockdown</td>\n",
       "      <td>american_behav_scientists</td>\n",
       "      <td>0.000270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>before-lockdown</td>\n",
       "      <td>behav_analysis</td>\n",
       "      <td>0.000021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lockdown</td>\n",
       "      <td>behav_analysis</td>\n",
       "      <td>0.000059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>before-lockdown</td>\n",
       "      <td>behav_change</td>\n",
       "      <td>0.000103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>lockdown</td>\n",
       "      <td>behav_change</td>\n",
       "      <td>0.000353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>before-lockdown</td>\n",
       "      <td>behav_econ</td>\n",
       "      <td>0.000206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>lockdown</td>\n",
       "      <td>behav_econ</td>\n",
       "      <td>0.000282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>before-lockdown</td>\n",
       "      <td>behav_insight</td>\n",
       "      <td>0.000041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>lockdown</td>\n",
       "      <td>behav_insight</td>\n",
       "      <td>0.000094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>before-lockdown</td>\n",
       "      <td>behav_insights_team</td>\n",
       "      <td>0.001382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>lockdown</td>\n",
       "      <td>behav_insights_team</td>\n",
       "      <td>0.000611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>before-lockdown</td>\n",
       "      <td>behav_science</td>\n",
       "      <td>0.002145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>lockdown</td>\n",
       "      <td>behav_science</td>\n",
       "      <td>0.002633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>before-lockdown</td>\n",
       "      <td>chater</td>\n",
       "      <td>0.000021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>lockdown</td>\n",
       "      <td>chater</td>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>before-lockdown</td>\n",
       "      <td>halpern</td>\n",
       "      <td>0.000722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>lockdown</td>\n",
       "      <td>halpern</td>\n",
       "      <td>0.000353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>before-lockdown</td>\n",
       "      <td>michie</td>\n",
       "      <td>0.000907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>lockdown</td>\n",
       "      <td>michie</td>\n",
       "      <td>0.000999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>before-lockdown</td>\n",
       "      <td>nudge</td>\n",
       "      <td>0.000969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>lockdown</td>\n",
       "      <td>nudge</td>\n",
       "      <td>0.000611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>before-lockdown</td>\n",
       "      <td>nudge_choice</td>\n",
       "      <td>0.000021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>lockdown</td>\n",
       "      <td>nudge_choice</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>before-lockdown</td>\n",
       "      <td>nudge_paternalism</td>\n",
       "      <td>0.000021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>lockdown</td>\n",
       "      <td>nudge_paternalism</td>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>before-lockdown</td>\n",
       "      <td>psychology</td>\n",
       "      <td>0.000969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>lockdown</td>\n",
       "      <td>psychology</td>\n",
       "      <td>0.001175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>before-lockdown</td>\n",
       "      <td>spi-b</td>\n",
       "      <td>0.000144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>lockdown</td>\n",
       "      <td>spi-b</td>\n",
       "      <td>0.000976</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        time_window                      kword       nkf\n",
       "0   before-lockdown  american_behav_scientists  0.000351\n",
       "1          lockdown  american_behav_scientists  0.000270\n",
       "2   before-lockdown             behav_analysis  0.000021\n",
       "3          lockdown             behav_analysis  0.000059\n",
       "4   before-lockdown               behav_change  0.000103\n",
       "5          lockdown               behav_change  0.000353\n",
       "6   before-lockdown                 behav_econ  0.000206\n",
       "7          lockdown                 behav_econ  0.000282\n",
       "8   before-lockdown              behav_insight  0.000041\n",
       "9          lockdown              behav_insight  0.000094\n",
       "10  before-lockdown        behav_insights_team  0.001382\n",
       "11         lockdown        behav_insights_team  0.000611\n",
       "12  before-lockdown              behav_science  0.002145\n",
       "13         lockdown              behav_science  0.002633\n",
       "14  before-lockdown                     chater  0.000021\n",
       "15         lockdown                     chater  0.000012\n",
       "16  before-lockdown                    halpern  0.000722\n",
       "17         lockdown                    halpern  0.000353\n",
       "18  before-lockdown                     michie  0.000907\n",
       "19         lockdown                     michie  0.000999\n",
       "20  before-lockdown                      nudge  0.000969\n",
       "21         lockdown                      nudge  0.000611\n",
       "22  before-lockdown               nudge_choice  0.000021\n",
       "23         lockdown               nudge_choice  0.000000\n",
       "24  before-lockdown          nudge_paternalism  0.000021\n",
       "25         lockdown          nudge_paternalism  0.000012\n",
       "26  before-lockdown                 psychology  0.000969\n",
       "27         lockdown                 psychology  0.001175\n",
       "28  before-lockdown                      spi-b  0.000144\n",
       "29         lockdown                      spi-b  0.000976"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kword_agg_nkf_long"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keyword document frequency per time windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kword_df_agg = kword_df.reset_index(['id']).groupby('time_window').agg(\n",
    "    article_count=('id', 'count')).merge(\n",
    "                        kword_df.groupby('time_window').sum(),\n",
    "                        on='time_window')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kword_agg_rdf = kword_df_agg.iloc[:, 1:].div(kword_df_agg.article_count, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kword_rdf_agg_long = pd.melt(\n",
    "                    kword_agg_rdf.reset_index(),\n",
    "                    id_vars=['time_window'],\n",
    "                    var_name='kword',\n",
    "                    value_name='rdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kword_rdf_agg_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Median normalised keyword frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the `median nkf` is calculated only considering the keywords' nkf values and not all words' or all nouns' nkf. So the meaning of High Frequent and Low Frequent keywords - i.e., above the median and below the median frequently keywords - must be interpreted relatively to the use of keywords only and not to all words or nouns used in the articles.\n",
    "\n",
    "An alternative apporach would be to set a threhold value or calculate the normalised word frequencies for all words (or nouns) in the articles and its median (more time consuming as it will require re-do some pre-existing steps)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nkf_medians = kword_agg_nkf_long.groupby('time_window').agg({'nkf':'median'})\n",
    "# print(nkf_medians)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# thanks to \"transformation\"\n",
    "# kword_agg_nkf_long['above_median'] = kword_agg_nkf_long['nkf'] - kword_agg_nkf_long.groupby('time_window')['nkf'].transform('median') > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nkf_median = kword_agg_nkf_long.nkf.median()\n",
    "kword_agg_nkf_long['nkf_above_median'] = kword_agg_nkf_long['nkf'] - nkf_median > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kword_agg_nkf_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truthvalue2type_dict = {\n",
    "    False: \"low\",\n",
    "    True: \"high\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kword_agg_nkf_long[\"nkf_type\"] = kword_agg_nkf_long.nkf_above_median.apply(lambda row: truthvalue2type_dict.get(row))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which keywords have high vs low (above vs below median) normalised corpus frequency in the two time windows? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kword_agg_nkf_long.groupby(['time_window', 'nkf_type']).kword.apply(list).reset_index(\n",
    "    name='kwords').pivot(index='time_window', columns='nkf_type')['kwords']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How has a keyword's corpus frequency changed across time windows?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kword_agg_nkf_long.pivot(index='kword', columns='time_window')['nkf_type']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lack of change for most keywords must be partially explained by the fact that high vs low are defined with respect to the keywords' median keyword frequency rather than the median frequency calculated from all words' frequencies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Median relative document frequency by time window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf_median = kword_rdf_agg_long.rdf.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kword_rdf_agg_long['rdf_above_median'] = kword_rdf_agg_long['rdf'] - rdf_median > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kword_rdf_agg_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kword_rdf_agg_long[\"rdf_type\"] = kword_rdf_agg_long.rdf_above_median.apply(lambda row: truthvalue2type_dict.get(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kword_rdf_agg_long"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which keywords have high vs low (above vs below median) relative doc frequency in the two time windows? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kword_rdf_agg_long.groupby(['time_window', 'rdf_type']).kword.apply(list).reset_index(\n",
    "    name='kwords').pivot(index='time_window', columns='rdf_type')['kwords']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kword_rdf_agg_long.pivot(index='kword', columns='time_window')['rdf_type']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine the two datasets together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kword_agg_nkf_rdf = kword_agg_nkf_long.merge(kword_rdf_agg_long, on = ['time_window', 'kword'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-lockdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kword_agg_nkf_rdf[kword_agg_nkf_rdf.time_window == \"before-lockdown\"].groupby(['nkf_type', 'rdf_type']).kword.apply(list).reset_index(\n",
    "    name='kwords').pivot(index='nkf_type', columns='rdf_type')['kwords']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lockdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kword_agg_nkf_rdf[kword_agg_nkf_rdf.time_window == \"lockdown\"].groupby(['nkf_type', 'rdf_type']).kword.apply(list).reset_index(\n",
    "    name='kwords').pivot(index='nkf_type', columns='rdf_type')['kwords']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does not seem to provide great insights as keywords which have an above-median normalised keyword frequency also have an above-average relative document frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Co-occurrence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove keywords that do not appear in our corpus\n",
    "\n",
    "Our keywords were theory driven so some do not appear in the corpus. Let's remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kword_df.drop(['irrational_econ', 'behav_policy'], inplace=True, axis=1)\n",
    "kword_rawfreqs.drop(['irrational_econ', 'behav_policy'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate before-lockdown vs lockdown data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kword_df_before = kword_df[kword_df.index.get_level_values('time_window').isin(['before-lockdown'])]\n",
    "kword_df_lock = kword_df[kword_df.index.get_level_values('time_window').isin(['lockdown'])]\n",
    "kword_rawfreqs_before = kword_rawfreqs[kword_rawfreqs.index.get_level_values('time_window').isin(['before-lockdown'])]\n",
    "kword_rawfreqs_lock = kword_rawfreqs[kword_rawfreqs.index.get_level_values('time_window').isin(['lockdown'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simpson' coefficient\n",
    "\n",
    "Another approach is Simpson coefficient, which has been reported to work well to represent co-occurrence even for keywords with a low appearence count in a document.\n",
    "\n",
    "Ref: \n",
    "https://onlinelibrary.wiley.com/doi/pdf/10.1002/ecj.10347\n",
    "\n",
    "https://www.aclweb.org/anthology/C12-2049.pdf\n",
    "\n",
    "https://www.aclweb.org/anthology/J05-4002.pdf\n",
    "\n",
    "`Simpson coefficient = count(w1, w2) / min(count(w1), count(w2))`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "def calc_simpson(yn_occurence_data, kwords_list, prefix=\"\"):\n",
    "    # keyword document occurrence\n",
    "    kword_docfreqs = yn_occurence_data.sum(axis=0)\n",
    "    # keywords co-occurrence matrix\n",
    "    kword_cooccurences = yn_occurence_data.values.T.dot(yn_occurence_data.values)\n",
    "    np.fill_diagonal(kword_cooccurences, 0)\n",
    "    kwords = yn_occurence_data.columns\n",
    "    kword_cooccurences = pd.DataFrame(kword_cooccurences, index=kwords, columns=kwords)\n",
    "    kword_cooccurences = kword_cooccurences.stack()\n",
    "    \n",
    "    \n",
    "    def _simpson(w1, w2):\n",
    "        # print(f\"{w1}: {kword_docfreqs[w1]}\")\n",
    "        # print(f\"{w2}: {kword_docfreqs[w2]}\")\n",
    "        # print(f\"coocc: {kword_cooccurences[w1][w2]}\")\n",
    "        try:\n",
    "            return kword_cooccurences[w1][w2]/ (min(kword_docfreqs[w1],kword_docfreqs[w2]))\n",
    "        except (ValueError, ZeroDivisionError) as err: # one of the two individual counts are 0\n",
    "            return np.nan\n",
    "        \n",
    "    def simpson(kwords_list: list) -> list:\n",
    "        coefs = []\n",
    "        for pair in combinations(kwords_list, r=2):\n",
    "            coefs.append((*pair, _simpson(*pair), kword_cooccurences[pair[0]][pair[1]], kword_docfreqs[pair[0]], kword_docfreqs[pair[1]] ))\n",
    "        return coefs\n",
    "    \n",
    "    simpsons = simpson(kwords_list=kwords_list)\n",
    "    simspons_df = pd.DataFrame(simpsons, columns=['source', 'target', f'{prefix}_weight', f'{prefix}_co-occ', f'{prefix}_source_docfreq', f'{prefix}_docfreq'])\n",
    "    \n",
    "    return simspons_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwords = kword_df_before.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "before_simpson_coefs = calc_simpson(yn_occurence_data=kword_df_before, kwords_list=kwords, prefix=\"bef\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lock_simpson_coefs = calc_simpson(yn_occurence_data=kword_df_lock, kwords_list=kwords, prefix=\"lock\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "before_simpson_coefs.sort_values('bef_weight', ascending=False)[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lock_simpson_coefs.sort_values('lock_weight', ascending=False)[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge the two to compare them more easily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simpsons_coefs = before_simpson_coefs.merge(lock_simpson_coefs, on = ['source', 'target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simpsons_coefs[['source', 'target', 'bef_weight', 'lock_weight']][:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trend_in_cooccurrence(score1, score2):\n",
    "    if ((score1 == 0.0) or (np.isnan(score1))) and ((score2 == 0.0) or (np.isnan(score2))):\n",
    "        return \"never\"\n",
    "    if ((score1 != 0.0) and (~np.isnan(score1))) and ((score2 != 0.0) and (~np.isnan(score2))):\n",
    "        return \"stayed\"\n",
    "    if ((score1 != 0.0) and (~np.isnan(score1))) and ((score2 == 0.0) or (np.isnan(score2))):\n",
    "        return \"ended\"\n",
    "    if ((score1 == 0.0) or (np.isnan(score1))) and ((score2 != 0.0) and (~np.isnan(score2))):\n",
    "        return \"started\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simpsons_coefs['weights_trend1'] = simpsons_coefs.apply(lambda row: trend_in_cooccurrence(row['bef_weight'], row['lock_weight']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simpsons_coefs[['source', 'target', 'bef_weight', 'lock_weight','weights_trend1']][:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Co-occurrences that started during lock-down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.array(simpsons_coefs[simpsons_coefs.weights_trend1 == \"started\"][['source', 'target']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Co-occurrences that ended during lock-down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(simpsons_coefs[simpsons_coefs.weights_trend1 == \"ended\"][['source', 'target']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Co-occurrences that remained during lock-down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(simpsons_coefs[simpsons_coefs.weights_trend1 == \"stayed\"][['source', 'target']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network based on Simpson's coefficient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before lockdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop NaN cases and 0.0 values\n",
    "before_simpson_coefs.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "before_simpson_coefs = before_simpson_coefs[before_simpson_coefs.bef_weight > 0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "before_simpson_graph = nx.from_pandas_edgelist(before_simpson_coefs[['source', 'target', 'bef_weight']], edge_attr=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a look at one\n",
    "print(nx.to_dict_of_dicts(before_simpson_graph).get('michie'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract weights, we'll use them for plotting\n",
    "before_simpson_graph_weights = list(nx.get_edge_attributes(before_simpson_graph,'bef_weight').values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(30,30))   \n",
    "nx.draw_networkx(before_simpson_graph, \n",
    "                 with_labels=True, \n",
    "                 edge_color=before_simpson_graph_weights,\n",
    "                 width=3,\n",
    "                 node_color='lightgreen',\n",
    "                 font_size=20,\n",
    "                 font_color='red',\n",
    "                 font_weight=3,\n",
    "                 edge_cmap=plt.cm.Blues\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### During lockdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop NaN cases and 0.0 values\n",
    "lock_simpson_coefs.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lock_simpson_coefs = lock_simpson_coefs[lock_simpson_coefs.lock_weight > 0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lock_simpson_graph = nx.from_pandas_edgelist(lock_simpson_coefs[['source', 'target', 'lock_weight']], edge_attr=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a look at one\n",
    "print(nx.to_dict_of_dicts(lock_simpson_graph).get('michie'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract weights, we'll use them for plotting\n",
    "lock_simpson_graph_weights = list(nx.get_edge_attributes(lock_simpson_graph,'lock_weight').values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(30,30))   \n",
    "nx.draw_networkx(lock_simpson_graph, \n",
    "                 with_labels=True, \n",
    "                 edge_color=lock_simpson_graph_weights,\n",
    "                 width=3,\n",
    "                 node_color='lightgreen',\n",
    "                 font_size=20,\n",
    "                 font_color='red',\n",
    "                 font_weight=3,\n",
    "                 edge_cmap=plt.cm.Blues\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lock_simpson_coefs[(lock_simpson_coefs.source == \"nudge_paternalism\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lock_simpson_coefs[(lock_simpson_coefs.target == \"nudge_paternalism\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dice coefficient\n",
    "\n",
    "Another approach is the Dice coefficient, which should not inflate the importance of co-occurrence for keywords with a very low appearence count in the corpus.\n",
    "\n",
    "Ref: \n",
    "https://onlinelibrary.wiley.com/doi/pdf/10.1002/ecj.10347\n",
    "\n",
    "https://www.aclweb.org/anthology/C12-2049.pdf\n",
    "\n",
    "https://www.aclweb.org/anthology/J05-4002.pdf\n",
    "\n",
    "`Dice coefficient = (2 * count(w1, w2)) / (count(w1) + count(w2))`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "def calc_dice(yn_occurence_data, kwords_list, prefix=\"\"):\n",
    "    # keyword document occurrence\n",
    "    kword_docfreqs = yn_occurence_data.sum(axis=0)\n",
    "    # keywords co-occurrence matrix\n",
    "    kword_cooccurences = yn_occurence_data.values.T.dot(yn_occurence_data.values)\n",
    "    np.fill_diagonal(kword_cooccurences, 0)\n",
    "    kwords = yn_occurence_data.columns\n",
    "    kword_cooccurences = pd.DataFrame(kword_cooccurences, index=kwords, columns=kwords)\n",
    "    kword_cooccurences = kword_cooccurences.stack()\n",
    "    \n",
    "    \n",
    "    def _dice(w1, w2):\n",
    "        # print(f\"{w1}: {kword_docfreqs[w1]}\")\n",
    "        # print(f\"{w2}: {kword_docfreqs[w2]}\")\n",
    "        # print(f\"coocc: {kword_cooccurences[w1][w2]}\")\n",
    "        try:\n",
    "            return (2 * kword_cooccurences[w1][w2]) / (kword_docfreqs[w1] + kword_docfreqs[w2])\n",
    "        except (ValueError, ZeroDivisionError) as err: # one of the two individual counts are 0\n",
    "            return np.nan\n",
    "        \n",
    "    def dice(kwords_list: list) -> list:\n",
    "        coefs = []\n",
    "        for pair in combinations(kwords_list, r=2):\n",
    "            coefs.append((*pair, _dice(*pair), kword_cooccurences[pair[0]][pair[1]], kword_docfreqs[pair[0]], kword_docfreqs[pair[1]] ))\n",
    "        return coefs\n",
    "    \n",
    "    dices = dice(kwords_list=kwords_list)\n",
    "    dices_df = pd.DataFrame(dices, columns=['source', 'target', f'{prefix}_weight', f'{prefix}_co-occ', f'{prefix}_source_docfreq', f'{prefix}_target_docfreq'])\n",
    "    \n",
    "    return dices_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwords = kword_df_before.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "before_dice_coefs = calc_dice(yn_occurence_data=kword_df_before, kwords_list=kwords, prefix=\"bef\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lock_dice_coefs = calc_dice(yn_occurence_data=kword_df_lock, kwords_list=kwords, prefix=\"lock\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "before_dice_coefs.sort_values('bef_weight', ascending=False)[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lock_dice_coefs.sort_values('lock_weight', ascending=False)[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge the two to compare them more easily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_coefs = before_dice_coefs.merge(lock_dice_coefs, on = ['source', 'target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_coefs[['source', 'target', 'bef_weight', 'lock_weight']][40:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trend_in_cooccurrence(score1, score2):\n",
    "    if ((score1 == 0.0) or (np.isnan(score1))) and ((score2 == 0.0) or (np.isnan(score2))):\n",
    "        return \"never\"\n",
    "    if ((score1 != 0.0) and (~np.isnan(score1))) and ((score2 != 0.0) and (~np.isnan(score2))):\n",
    "        return \"stayed\"\n",
    "    if ((score1 != 0.0) and (~np.isnan(score1))) and ((score2 == 0.0) or (np.isnan(score2))):\n",
    "        return \"ended\"\n",
    "    if ((score1 == 0.0) or (np.isnan(score1))) and ((score2 != 0.0) and (~np.isnan(score2))):\n",
    "        return \"started\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_coefs['weights_trend1'] = dice_coefs.apply(lambda row: trend_in_cooccurrence(row['bef_weight'], row['lock_weight']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_coefs[['source', 'target', 'bef_weight', 'lock_weight','weights_trend1']][:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Co-occurrences that started during lock-down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.array(dice_coefs[dice_coefs.weights_trend1 == \"started\"][['source', 'target']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Co-occurrences that ended during lock-down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(dice_coefs[dice_coefs.weights_trend1 == \"ended\"][['source', 'target']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Co-occurrences that remained during lock-down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(dice_coefs[dice_coefs.weights_trend1 == \"stayed\"][['source', 'target']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network based on Dice coefficient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before lockdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop NaN cases and 0.0 values\n",
    "before_dice_coefs.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "before_dice_coefs = before_dice_coefs[before_dice_coefs.bef_weight > 0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "before_dice_graph = nx.from_pandas_edgelist(before_dice_coefs[['source', 'target', 'bef_weight']], edge_attr=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a look at one\n",
    "print(nx.to_dict_of_dicts(before_dice_graph).get('michie'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract weights, we'll use them for plotting\n",
    "before_dice_graph_weights = list(nx.get_edge_attributes(before_dice_graph,'bef_weight').values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(30,30))   \n",
    "nx.draw_networkx(before_dice_graph, \n",
    "                 with_labels=True, \n",
    "                 edge_color=before_dice_graph_weights,\n",
    "                 width=3,\n",
    "                 node_color='lightgreen',\n",
    "                 font_size=20,\n",
    "                 font_color='red',\n",
    "                 font_weight=3,\n",
    "                 edge_cmap=plt.cm.Blues\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### During lockdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop NaN cases and 0.0 values\n",
    "lock_dice_coefs.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lock_dice_coefs = lock_dice_coefs[lock_dice_coefs.lock_weight > 0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lock_dice_graph = nx.from_pandas_edgelist(lock_dice_coefs[['source', 'target', 'lock_weight']], edge_attr=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a look at one\n",
    "print(nx.to_dict_of_dicts(lock_dice_graph).get('michie'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract weights, we'll use them for plotting\n",
    "lock_dice_weights = list(nx.get_edge_attributes(lock_dice_graph,'lock_weight').values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(30,30))   \n",
    "nx.draw_networkx(lock_dice_graph, \n",
    "                 with_labels=True, \n",
    "                 edge_color=lock_simpson_dice_weights,\n",
    "                 width=3,\n",
    "                 node_color='lightgreen',\n",
    "                 font_size=20,\n",
    "                 font_color='red',\n",
    "                 font_weight=3,\n",
    "                 edge_cmap=plt.cm.Blues\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Characteristics of the two networks and nodes\n",
    "\n",
    "Main ref: https://programminghistorian.org/en/lessons/exploring-and-analyzing-network-data-with-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of nodes (keywords that co-occured)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of keywords co-occurring before-lockdown:\", len(before_dice_graph.nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of keywords co-occurring during-lockdown:\", len(lock_dice_graph.nodes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network density"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Network density\n",
    "= ratio between actual number of connections between nodes and maximum possible number of connections.\n",
    "\n",
    "Give a sense of how closely knit the network is, a higher value (within [0,1]) indicates a more cohesive network, so a set of keywords that do tend to co-occur.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "before_density = nx.density(before_dice_graph)\n",
    "print(\"Network density (before lockdown):\", before_density)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lock_density = nx.density(lock_dice_graph)\n",
    "print(\"Network density (during lockdown):\", lock_density)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Network density has increased during lockdown compared to pre-lockdown. \n",
    "\n",
    "Interpretation: an increase in the general tendency of keywords to co-occur together in the same documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network Clustering Coefficient\n",
    "\n",
    "= n^ of connections between the neighbour nodes of a node / maximum possible number of connections between its neighbour nodes\n",
    "\n",
    "(neighbour nodes are the nodes directly connected to a node).\n",
    "\n",
    "A measure of the degree to which nodes in a graph tend to cluster together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "before_clustcoef = nx.average_clustering(before_dice_graph, weight='bef_weights')\n",
    "print(\"Network clustering coefficient (before lockdown):\", before_clustcoef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lock_clustcoef = nx.average_clustering(lock_dice_graph, weight='lock_weights')\n",
    "print(\"Network clustering coefficient (during lockdown):\", lock_clustcoef)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remained stable. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Centrality measures\n",
    "\n",
    "Identify nodes (keywords) that are more important in the networks and compare the ranking them over time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Node Degree\n",
    "\n",
    "The number of connection a node has. \n",
    "\n",
    "Here is with how many different keywords does each keyword co-occur?\n",
    "Note that this is likely to be proportional to the keyword's frequency. Something we can also report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_node_degree(graph):\n",
    "    node_degree_dict = {}\n",
    "    for node in graph.nodes:\n",
    "        node_degree_dict[node] = nx.degree(graph, node)\n",
    "    return node_degree_dict    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before lockdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "before_node_degrees = pd.Series(get_node_degree(before_dice_graph)).sort_values(ascending=False)\n",
    "print(before_node_degrees)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During lockdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lock_node_degrees = pd.Series(get_node_degree(lock_dice_graph)).sort_values(ascending=False)\n",
    "print(lock_node_degrees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternative way to calculate it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "before_degree_dict = dict(before_dice_graph.degree(before_dice_graph.nodes()))\n",
    "nx.set_node_attributes(before_dice_graph, before_degree_dict, 'degree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lock_degree_dict = dict(lock_dice_graph.degree(lock_dice_graph.nodes()))\n",
    "nx.set_node_attributes(lock_dice_graph, lock_degree_dict, 'degree')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Node Betweeness Centrality\n",
    "\n",
    "Betweenness centrality doesn’t care about the number of edges any one node or set of nodes has. Betweenness centrality looks at all the shortest paths that pass through a particular node.\n",
    "\n",
    "So a keyword with a high betweeness centrality is a keyword that works as a bridge by connecting several different other keywords - i.e., it is discussed in articles with a wider variety of other keywords."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-lockdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "before_betweenness_dict = nx.betweenness_centrality(before_dice_graph) \n",
    "\n",
    "# Assign each to an attribute in your network\n",
    "nx.set_node_attributes(before_dice_graph, before_betweenness_dict, 'betweenness')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(before_betweenness_dict.items(), key=itemgetter(1), reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare degree and between centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Then find and print their degree\n",
    "for tb in sorted(before_betweenness_dict.items(), key=itemgetter(1), reverse=True): \n",
    "    degree = before_degree_dict[tb[0]] # Use degree_dict to access a node's degree\n",
    "    print(\"Name:\", tb[0], \"| Betweenness Centrality:\", tb[1], \"| Degree:\", degree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During lockdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lock_betweenness_dict = nx.betweenness_centrality(lock_dice_graph) \n",
    "\n",
    "# Assign each to an attribute in your network\n",
    "nx.set_node_attributes(lock_dice_graph, lock_betweenness_dict, 'betweenness')\n",
    "\n",
    "\n",
    "sorted(lock_betweenness_dict.items(), key=itemgetter(1), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.1 64-bit ('venv': venv)",
   "language": "python",
   "name": "python38164bitvenvvenvdde169c8e66848db85d258e4e769d548"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
